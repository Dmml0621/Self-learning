{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-80IIRVI.mshome.net:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=test>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = SparkContext(\"local\", \"test\")\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize(range(1, 11), 4)\n",
    "rdd.take(100)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize(range(1, 11), 4)\n",
    "rdd_map = rdd.map(lambda x: 2 * x)\n",
    "print(rdd.collect())\n",
    "print(rdd_map.collect())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello SamShare', 'hello PySpark']\n",
      "[['hello', 'SamShare'], ['hello', 'PySpark']]\n",
      "['hello', 'SamShare', 'hello', 'PySpark']\n"
     ]
    }
   ],
   "source": [
    "rdd2 = sc.parallelize([\"hello SamShare\", \"hello PySpark\"])\n",
    "print(rdd2.collect())\n",
    "print(rdd2.map(lambda x: x.split(\" \")).collect())\n",
    "print(rdd2.flatMap(lambda x: x.split(\" \")).collect())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[2, 4, 6, 8, 10]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize(range(1, 11), 4)\n",
    "print(rdd.collect())\n",
    "print(rdd.filter(lambda x: x % 2 == 0).collect())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 4, 8, 8, 8, 8, 16, 32, 32]\n",
      "[2, 4, 8, 16, 32]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([2, 2, 4, 8, 8, 8, 8, 16, 32, 32])\n",
    "print(rdd.collect())\n",
    "print(rdd.distinct().collect())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduceByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 1), ('b', 1), ('a', 1)]\n",
      "[('a', 2), ('b', 1)]\n"
     ]
    }
   ],
   "source": [
    "from operator import add\n",
    "rdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\n",
    "print(rdd.collect())\n",
    "print(rdd.reduceByKey(add).collect())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mapPartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n",
      "[3, 7]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4], 2)\n",
    "def f(iterator):\n",
    "    yield sum(iterator)\n",
    "print(rdd.collect())\n",
    "print(rdd.mapPartitions(f).collect())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sortBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1', 3), ('2', 5), ('a', 1), ('b', 2), ('d', 4)]\n",
      "[('a', 1), ('b', 2), ('1', 3), ('d', 4), ('2', 5)]\n"
     ]
    }
   ],
   "source": [
    "tmp = [('a', 1), ('b', 2), ('1', 3), ('d', 4), ('2', 5)]\n",
    "print(sc.parallelize(tmp).sortBy(lambda x: x[0]).collect())\n",
    "print(sc.parallelize(tmp).sortBy(lambda x: x[1]).collect())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subtract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 1), ('b', 4), ('b', 5)]\n"
     ]
    }
   ],
   "source": [
    "x = sc.parallelize([(\"a\", 1), (\"b\", 4), (\"b\", 5), (\"a\", 3)])\n",
    "y = sc.parallelize([(\"a\", 3), (\"c\", None)])\n",
    "print(sorted(x.subtract(y).collect()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 2, 3, 1, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([1, 1, 2, 3])\n",
    "print(rdd.union(rdd).collect())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 3]\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([1, 10, 2, 3, 4, 5, 2, 3])\n",
    "rdd2 = sc.parallelize([1, 6, 2, 3, 7, 8])\n",
    "print(rdd1.intersection(rdd2).collect())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cartesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1), (1, 2), (1, 3), (2, 1), (2, 2), (2, 3), (3, 1), (3, 2), (3, 3)]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([1, 2, 3])\n",
    "print(sorted(rdd.cartesian(rdd).collect()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1000), (1, 1001), (2, 1002), (3, 1003), (4, 1004)]\n"
     ]
    }
   ],
   "source": [
    "x = sc.parallelize(range(0, 5))\n",
    "y = sc.parallelize(range(1000, 1005))\n",
    "print(x.zip(y).collect())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zipWithIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('LiLei', 0), ('Hanmeimei', 1), ('Lily', 2), ('Lucy', 3), ('Ann', 4), ('Dachui', 5), ('RuHua', 6)]\n"
     ]
    }
   ],
   "source": [
    "rdd_name = sc.parallelize([\"LiLei\", \"Hanmeimei\", \"Lily\", \"Lucy\", \"Ann\", \"Dachui\", \"RuHua\"])\n",
    "rdd_index = rdd_name.zipWithIndex()\n",
    "print(rdd_index.collect())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "groupByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 2), ('b', 1)]\n",
      "[('a', [3, 1]), ('b', [1])]\n",
      "[('a', 4), ('b', 1)]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([(\"a\", 3), (\"b\", 1), (\"a\", 1)])\n",
    "print(sorted(rdd.groupByKey().mapValues(len).collect()))\n",
    "print(sorted(rdd.groupByKey().mapValues(list).collect()))\n",
    "print(sorted(rdd.groupByKey().mapValues(sum).collect()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sortByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('d', 4), ('b', 2), ('a', 1), ('2', 5), ('1', 3)]\n"
     ]
    }
   ],
   "source": [
    "tmp = [('a', 1), ('b', 2), ('1', 3), ('d', 4), ('2', 5)]\n",
    "print(sc.parallelize(tmp).sortByKey(False, 1).collect())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', (1, 2)), ('a', (1, 3))]\n",
      "[('a', (2, 1)), ('a', (3, 1))]\n"
     ]
    }
   ],
   "source": [
    "x = sc.parallelize([(\"a\", 1), (\"b\", 4)])\n",
    "y = sc.parallelize([(\"a\", 2), (\"a\", 3)])\n",
    "print(sorted(x.join(y).collect()))\n",
    "print(sorted(y.join(x).collect()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "leftOuterJoin/rightOuterJoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', (1, 2)), ('b', (4, None))]\n",
      "[('a', (1, 2))]\n"
     ]
    }
   ],
   "source": [
    "x = sc.parallelize([(\"a\", 1), (\"b\", 4)])\n",
    "y = sc.parallelize([(\"a\", 2)])\n",
    "print(sorted(x.leftOuterJoin(y).collect()))\n",
    "print(sorted(x.rightOuterJoin(y).collect()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize(range(0, 5))\n",
    "rdd_collect = rdd.collect()\n",
    "print(rdd_collect)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(sc.parallelize([2, 3, 4]).first())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "collectAsMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 2, 3: 4}\n"
     ]
    }
   ],
   "source": [
    "print(sc.parallelize([(1, 2), (3, 4)]).collectAsMap())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize(range(10), 5)\n",
    "print(rdd.reduce(lambda x, y: x+y))\n",
    "print(rdd.reduce(add))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "countByKey/countByValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 2), ('b', 1)]\n",
      "[(('a', 1), 2), (('b', 1), 1)]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\n",
    "print(sorted(rdd.countByKey().items()))\n",
    "print(sorted(rdd.countByValue().items()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 1), ('b', 1), ('a', 1)]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\n",
    "print(rdd.take(5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "takeSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59, 55, 27, 70, 98]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize(range(100), 4)\n",
    "print(rdd.takeSample(True, 5, 42))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "foreach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize(range(10), 5)\n",
    "accum = sc.accumulator(0)\n",
    "rdd.foreach(lambda x: accum.add(x))\n",
    "print(accum.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SparkSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('testsql').getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SparkDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+\n",
      "| name|age|score|\n",
      "+-----+---+-----+\n",
      "|  Sam| 28|   88|\n",
      "|Flora| 28|   90|\n",
      "|  Run|  1|   60|\n",
      "+-----+---+-----+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([(\"Sam\", 28, 88), (\"Flora\", 28, 90), (\"Run\", 1, 60)])\n",
    "df = rdd.toDF([\"name\", \"age\", \"score\"])\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name  age  score\n",
      "0    Sam   28     88\n",
      "1  Flora   28     90\n",
      "2    Run    1     60\n",
      "+-----+---+-----+\n",
      "| name|age|score|\n",
      "+-----+---+-----+\n",
      "|  Sam| 28|   88|\n",
      "|Flora| 28|   90|\n",
      "|  Run|  1|   60|\n",
      "+-----+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([['Sam', 28, 88], ['Flora', 28, 90], ['Run', 1, 60]],\n",
    "                  columns=['name', 'age', 'score'])\n",
    "print(df)\n",
    "Spark_df = spark.createDataFrame(df)\n",
    "Spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+\n",
      "| name|age|score|\n",
      "+-----+---+-----+\n",
      "|  Sam| 28|   88|\n",
      "|Flora| 28|   90|\n",
      "|  Run|  1|   60|\n",
      "+-----+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_values = [['Sam', 28, 88], ['Flora', 28, 90], ['Run', 1, 60]]\n",
    "Spark_df = spark.createDataFrame(list_values, ['name', 'age', 'score'])\n",
    "Spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+-----+\n",
      "|_c0| name|age|score|\n",
      "+---+-----+---+-----+\n",
      "|  0|  Sam| 28|   88|\n",
      "|  1|Flora| 28|   90|\n",
      "+---+-----+---+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- score: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('test_csv.csv')\n",
    "\n",
    "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"delimiter\", \",\").csv(\"test_csv.csv\")\n",
    "df.show(2)\n",
    "df.printSchema()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SparkDataFrame API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
